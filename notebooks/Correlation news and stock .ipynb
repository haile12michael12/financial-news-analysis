{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6e8b299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6846 entries, 0 to 6845\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date          6846 non-null   object \n",
      " 1   Open          6846 non-null   float64\n",
      " 2   High          6846 non-null   float64\n",
      " 3   Low           6846 non-null   float64\n",
      " 4   Close         6846 non-null   float64\n",
      " 5   Adj Close     6846 non-null   float64\n",
      " 6   Volume        6846 non-null   int64  \n",
      " 7   Dividends     6846 non-null   float64\n",
      " 8   Stock Splits  6846 non-null   float64\n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 481.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4580 entries, 0 to 4579\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  4580 non-null   int64  \n",
      " 1   headline    4580 non-null   object \n",
      " 2   url         4580 non-null   object \n",
      " 3   publisher   4580 non-null   object \n",
      " 4   date        4580 non-null   object \n",
      " 5   stock       0 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 214.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from datetime import datetime\n",
    "\n",
    "# Load datasets with explicit date parsing\n",
    "stock_df = pd.read_csv('data/AMZN_historical_data.csv')\n",
    "news_df = pd.read_csv('data/raw_analyst_ratings_1.csv')\n",
    "# Set datetime index for stock data\n",
    "\n",
    "\n",
    "# Display basic information and the first few rows of each dataset\n",
    "stock_df_info = stock_df.info()\n",
    "news_df_info = news_df.info()\n",
    "\n",
    "# Step 1: Date Alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a5beb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "          Date      Open      High       Low     Close  Adj Close      Volume  \\\n",
       " 0  1997-05-15  0.121875  0.125000  0.096354  0.097917   0.097917  1443120000   \n",
       " 1  1997-05-16  0.098438  0.098958  0.085417  0.086458   0.086458   294000000   \n",
       " 2  1997-05-19  0.088021  0.088542  0.081250  0.085417   0.085417   122136000   \n",
       " 3  1997-05-20  0.086458  0.087500  0.081771  0.081771   0.081771   109344000   \n",
       " 4  1997-05-21  0.081771  0.082292  0.068750  0.071354   0.071354   377064000   \n",
       " \n",
       "    Dividends  Stock Splits  \n",
       " 0        0.0           0.0  \n",
       " 1        0.0           0.0  \n",
       " 2        0.0           0.0  \n",
       " 3        0.0           0.0  \n",
       " 4        0.0           0.0  ,\n",
       " None,\n",
       "    Unnamed: 0                                           headline  \\\n",
       " 0           0            Stocks That Hit 52-Week Highs On Friday   \n",
       " 1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
       " 2           2                      71 Biggest Movers From Friday   \n",
       " 3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
       " 4           4  B of A Securities Maintains Neutral on Agilent...   \n",
       " \n",
       "                                                  url          publisher  \\\n",
       " 0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
       " 1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
       " 2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
       " 3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
       " 4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
       " \n",
       "                         date  stock  \n",
       " 0  2020-06-05 10:30:54-04:00    NaN  \n",
       " 1  2020-06-03 10:45:20-04:00    NaN  \n",
       " 2  2020-05-26 04:30:07-04:00    NaN  \n",
       " 3  2020-05-22 12:45:06-04:00    NaN  \n",
       " 4  2020-05-22 11:38:59-04:00    NaN  )"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df_head = stock_df.head()\n",
    "news_df_head = news_df.head()\n",
    "\n",
    "stock_df_info, stock_df_head, news_df_info, news_df_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Normalize Dates\n",
    "news_df['date'] = pd.to_datetime(news_df['date'], errors='coerce').dt.date\n",
    "stock_df['Date'] = pd.to_datetime(stock_df['Date'], errors='coerce').dt.date\n",
    "\n",
    "# Step 2: Perform Sentiment Analysis using TextBlob\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(str(text)).sentiment.polarity\n",
    "\n",
    "news_df['sentiment'] = news_df['headline'].apply(get_sentiment)\n",
    "\n",
    "\n",
    "# Step 3: Aggregate Sentiment by Date\n",
    "daily_sentiment = news_df.groupby('date')['sentiment'].mean().reset_index()\n",
    "\n",
    "# Step 4: Compute Daily Stock Returns\n",
    "stock_df = stock_df.sort_values(by='Date')\n",
    "stock_df['return'] = stock_df['Close'].pct_change()\n",
    "\n",
    "\n",
    "# Step 5: Merge Datasets on Date\n",
    "merged_df = pd.merge(stock_df, daily_sentiment, how='inner', left_on='Date', right_on='date')\n",
    "\n",
    "# Step 6: Calculate Pearson Correlation\n",
    "correlation = merged_df[['return', 'sentiment']].corr().iloc[0, 1]\n",
    "\n",
    "# Display merged dataset head and correlation value\n",
    "merged_df_head = merged_df[['Date', 'Close', 'return', 'sentiment']].head()\n",
    "correlation, merged_df_head"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
